{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc = pd.read_csv('LIWC2015 Results.csv')\n",
    "uid = pd.read_csv('UID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>Authentic</th>\n",
       "      <th>Tone</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>...</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>latest headlines on cnn business dedudithitt i...</td>\n",
       "      <td>475</td>\n",
       "      <td>43.13</td>\n",
       "      <td>59.99</td>\n",
       "      <td>76.14</td>\n",
       "      <td>87.27</td>\n",
       "      <td>118.75</td>\n",
       "      <td>28.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>china wants to take a victory lap over its han...</td>\n",
       "      <td>483</td>\n",
       "      <td>57.16</td>\n",
       "      <td>66.81</td>\n",
       "      <td>75.04</td>\n",
       "      <td>52.99</td>\n",
       "      <td>120.75</td>\n",
       "      <td>27.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>coronavirus disinformation creates challenges ...</td>\n",
       "      <td>483</td>\n",
       "      <td>27.81</td>\n",
       "      <td>75.94</td>\n",
       "      <td>72.78</td>\n",
       "      <td>96.64</td>\n",
       "      <td>241.50</td>\n",
       "      <td>22.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>china coronavirus: eating wild animals made il...</td>\n",
       "      <td>498</td>\n",
       "      <td>59.82</td>\n",
       "      <td>69.21</td>\n",
       "      <td>93.13</td>\n",
       "      <td>60.02</td>\n",
       "      <td>99.60</td>\n",
       "      <td>31.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>china's economy could shrink for the first tim...</td>\n",
       "      <td>392</td>\n",
       "      <td>49.36</td>\n",
       "      <td>78.55</td>\n",
       "      <td>49.46</td>\n",
       "      <td>44.45</td>\n",
       "      <td>49.00</td>\n",
       "      <td>13.78</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A              B                                                  C   WC  \\\n",
       "0  0  new_xlnet.csv  latest headlines on cnn business dedudithitt i...  475   \n",
       "1  1  new_xlnet.csv  china wants to take a victory lap over its han...  483   \n",
       "2  2  new_xlnet.csv  coronavirus disinformation creates challenges ...  483   \n",
       "3  3  new_xlnet.csv  china coronavirus: eating wild animals made il...  498   \n",
       "4  4  new_xlnet.csv  china's economy could shrink for the first tim...  392   \n",
       "\n",
       "   Analytic  Clout  Authentic   Tone     WPS  Sixltr  ...  Comma  Colon  \\\n",
       "0     43.13  59.99      76.14  87.27  118.75   28.84  ...   0.21   0.21   \n",
       "1     57.16  66.81      75.04  52.99  120.75   27.33  ...   0.21   0.41   \n",
       "2     27.81  75.94      72.78  96.64  241.50   22.57  ...   0.21   0.00   \n",
       "3     59.82  69.21      93.13  60.02   99.60   31.93  ...   0.20   0.20   \n",
       "4     49.36  78.55      49.46  44.45   49.00   13.78  ...   0.26   0.26   \n",
       "\n",
       "   SemiC  QMark  Exclam  Dash  Quote  Apostro  Parenth  OtherP  \n",
       "0   0.21   0.42    0.21  0.21   1.05     0.84     0.42    0.21  \n",
       "1   0.21   0.21    0.21  0.21   0.41     0.41     0.41    0.21  \n",
       "2   0.21   0.21    0.21  0.21   0.62     0.41     0.21    0.21  \n",
       "3   0.20   0.80    0.20  0.20   0.00     0.20     0.00    0.20  \n",
       "4   0.26   1.02    2.55  0.77   0.77     1.02     0.51    0.26  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liwc = liwc.rename(columns = {\"B\": \"Filename\"} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Filename</th>\n",
       "      <th>UID</th>\n",
       "      <th>Flesch Reading Ease</th>\n",
       "      <th>Flesch-Kincaid</th>\n",
       "      <th>Fog Scale</th>\n",
       "      <th>SMOG Index</th>\n",
       "      <th>Automated Readability Index</th>\n",
       "      <th>Coleman-Liau Index</th>\n",
       "      <th>Linsear Write Formula</th>\n",
       "      <th>Dale-Chall Readability Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>latest headlines on cnn business dedudithitt i...</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.172917</td>\n",
       "      <td>11.845833</td>\n",
       "      <td>12.394583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.341667</td>\n",
       "      <td>14.3775</td>\n",
       "      <td>12.375</td>\n",
       "      <td>8.346667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>china wants to take a victory lap over its han...</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.521200</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>12.016000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.972000</td>\n",
       "      <td>13.1584</td>\n",
       "      <td>12.180</td>\n",
       "      <td>8.463200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>coronavirus disinformation creates challenges ...</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>63.118400</td>\n",
       "      <td>9.236000</td>\n",
       "      <td>10.264400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.060000</td>\n",
       "      <td>10.1776</td>\n",
       "      <td>11.440</td>\n",
       "      <td>6.477600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>china coronavirus: eating wild animals made il...</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.265200</td>\n",
       "      <td>11.748000</td>\n",
       "      <td>12.496000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.224000</td>\n",
       "      <td>14.2600</td>\n",
       "      <td>12.840</td>\n",
       "      <td>7.620400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>china's economy could shrink for the first tim...</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>76.644500</td>\n",
       "      <td>7.425000</td>\n",
       "      <td>9.033500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>5.5955</td>\n",
       "      <td>10.550</td>\n",
       "      <td>4.569500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           0  latest headlines on cnn business dedudithitt i...   \n",
       "1           1  china wants to take a victory lap over its han...   \n",
       "2           2  coronavirus disinformation creates challenges ...   \n",
       "3           3  china coronavirus: eating wild animals made il...   \n",
       "4           4  china's economy could shrink for the first tim...   \n",
       "\n",
       "        Filename  UID  Flesch Reading Ease  Flesch-Kincaid  Fog Scale  \\\n",
       "0  new_xlnet.csv  9.0            45.172917       11.845833  12.394583   \n",
       "1  new_xlnet.csv  9.0            45.521200       11.700000  12.016000   \n",
       "2  new_xlnet.csv  9.0            63.118400        9.236000  10.264400   \n",
       "3  new_xlnet.csv  9.0            46.265200       11.748000  12.496000   \n",
       "4  new_xlnet.csv  9.0            76.644500        7.425000   9.033500   \n",
       "\n",
       "   SMOG Index  Automated Readability Index  Coleman-Liau Index  \\\n",
       "0         0.0                    14.341667             14.3775   \n",
       "1         0.0                    13.972000             13.1584   \n",
       "2         0.0                    11.060000             10.1776   \n",
       "3         0.0                    14.224000             14.2600   \n",
       "4         0.0                     7.300000              5.5955   \n",
       "\n",
       "   Linsear Write Formula  Dale-Chall Readability Score  \n",
       "0                 12.375                      8.346667  \n",
       "1                 12.180                      8.463200  \n",
       "2                 11.440                      6.477600  \n",
       "3                 12.840                      7.620400  \n",
       "4                 10.550                      4.569500  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc = liwc.drop(columns = ['A', 'B', 'C'])\n",
    "uid = uid.drop(columns = 'Text', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9594"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# combine = pd.merge(uid, liwc, on=['Filename'], how='left')\n",
    "combine = pd.concat([uid, liwc], axis=1, sort=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Filename</th>\n",
       "      <th>UID</th>\n",
       "      <th>Flesch Reading Ease</th>\n",
       "      <th>Flesch-Kincaid</th>\n",
       "      <th>Fog Scale</th>\n",
       "      <th>SMOG Index</th>\n",
       "      <th>Automated Readability Index</th>\n",
       "      <th>Coleman-Liau Index</th>\n",
       "      <th>Linsear Write Formula</th>\n",
       "      <th>...</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.172917</td>\n",
       "      <td>11.845833</td>\n",
       "      <td>12.394583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.341667</td>\n",
       "      <td>14.3775</td>\n",
       "      <td>12.375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.521200</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>12.016000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.972000</td>\n",
       "      <td>13.1584</td>\n",
       "      <td>12.180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>63.118400</td>\n",
       "      <td>9.236000</td>\n",
       "      <td>10.264400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.060000</td>\n",
       "      <td>10.1776</td>\n",
       "      <td>11.440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.265200</td>\n",
       "      <td>11.748000</td>\n",
       "      <td>12.496000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.224000</td>\n",
       "      <td>14.2600</td>\n",
       "      <td>12.840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>76.644500</td>\n",
       "      <td>7.425000</td>\n",
       "      <td>9.033500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>5.5955</td>\n",
       "      <td>10.550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       Filename  UID  Flesch Reading Ease  Flesch-Kincaid  \\\n",
       "0           0  new_xlnet.csv  9.0            45.172917       11.845833   \n",
       "1           1  new_xlnet.csv  9.0            45.521200       11.700000   \n",
       "2           2  new_xlnet.csv  9.0            63.118400        9.236000   \n",
       "3           3  new_xlnet.csv  9.0            46.265200       11.748000   \n",
       "4           4  new_xlnet.csv  9.0            76.644500        7.425000   \n",
       "\n",
       "   Fog Scale  SMOG Index  Automated Readability Index  Coleman-Liau Index  \\\n",
       "0  12.394583         0.0                    14.341667             14.3775   \n",
       "1  12.016000         0.0                    13.972000             13.1584   \n",
       "2  10.264400         0.0                    11.060000             10.1776   \n",
       "3  12.496000         0.0                    14.224000             14.2600   \n",
       "4   9.033500         0.0                     7.300000              5.5955   \n",
       "\n",
       "   Linsear Write Formula  ...  Comma  Colon  SemiC  QMark  Exclam  Dash  \\\n",
       "0                 12.375  ...   0.21   0.21   0.21   0.42    0.21  0.21   \n",
       "1                 12.180  ...   0.21   0.41   0.21   0.21    0.21  0.21   \n",
       "2                 11.440  ...   0.21   0.00   0.21   0.21    0.21  0.21   \n",
       "3                 12.840  ...   0.20   0.20   0.20   0.80    0.20  0.20   \n",
       "4                 10.550  ...   0.26   0.26   0.26   1.02    2.55  0.77   \n",
       "\n",
       "   Quote  Apostro  Parenth  OtherP  \n",
       "0   1.05     0.84     0.42    0.21  \n",
       "1   0.41     0.41     0.41    0.21  \n",
       "2   0.62     0.41     0.21    0.21  \n",
       "3   0.00     0.20     0.00    0.20  \n",
       "4   0.77     1.02     0.51    0.26  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9594"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['new_xlnet.csv', 'new_gpt2.csv', 'new_human.csv', 'new_pplm.csv',\n",
       "       'new_gpt.csv', 'new_grover.csv', 'new_fair.csv', 'new_xlm.csv',\n",
       "       'new_ctrl.csv'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine['Filename'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = combine.drop(columns =  ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "\n",
    "for i in combine['Filename']:\n",
    "    if i == 'new_ctrl.csv':\n",
    "        label.append('ctrl')\n",
    "    elif i == 'new_gpt.csv':\n",
    "        label.append('gpt')\n",
    "    elif i == 'new_gpt2.csv':\n",
    "        label.append('gpt2')\n",
    "    elif i == 'new_grover.csv':\n",
    "        label.append('grover')\n",
    "    elif i == 'new_xlm.csv':\n",
    "        label.append('xlm')\n",
    "    elif i == 'new_xlnet.csv':\n",
    "        label.append('xlnet')\n",
    "    elif i == 'new_pplm.csv':\n",
    "        label.append('pplm')\n",
    "    elif i == 'new_human.csv':\n",
    "        label.append('human')\n",
    "    elif i == 'new_fair.csv':\n",
    "        label.append('fair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9594"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>UID</th>\n",
       "      <th>Flesch Reading Ease</th>\n",
       "      <th>Flesch-Kincaid</th>\n",
       "      <th>Fog Scale</th>\n",
       "      <th>SMOG Index</th>\n",
       "      <th>Automated Readability Index</th>\n",
       "      <th>Coleman-Liau Index</th>\n",
       "      <th>Linsear Write Formula</th>\n",
       "      <th>Dale-Chall Readability Score</th>\n",
       "      <th>...</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.172917</td>\n",
       "      <td>11.845833</td>\n",
       "      <td>12.394583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.341667</td>\n",
       "      <td>14.3775</td>\n",
       "      <td>12.375</td>\n",
       "      <td>8.346667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.521200</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>12.016000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.972000</td>\n",
       "      <td>13.1584</td>\n",
       "      <td>12.180</td>\n",
       "      <td>8.463200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>63.118400</td>\n",
       "      <td>9.236000</td>\n",
       "      <td>10.264400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.060000</td>\n",
       "      <td>10.1776</td>\n",
       "      <td>11.440</td>\n",
       "      <td>6.477600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.265200</td>\n",
       "      <td>11.748000</td>\n",
       "      <td>12.496000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.224000</td>\n",
       "      <td>14.2600</td>\n",
       "      <td>12.840</td>\n",
       "      <td>7.620400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new_xlnet.csv</td>\n",
       "      <td>9.0</td>\n",
       "      <td>76.644500</td>\n",
       "      <td>7.425000</td>\n",
       "      <td>9.033500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>5.5955</td>\n",
       "      <td>10.550</td>\n",
       "      <td>4.569500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Filename  UID  Flesch Reading Ease  Flesch-Kincaid  Fog Scale  \\\n",
       "0  new_xlnet.csv  9.0            45.172917       11.845833  12.394583   \n",
       "1  new_xlnet.csv  9.0            45.521200       11.700000  12.016000   \n",
       "2  new_xlnet.csv  9.0            63.118400        9.236000  10.264400   \n",
       "3  new_xlnet.csv  9.0            46.265200       11.748000  12.496000   \n",
       "4  new_xlnet.csv  9.0            76.644500        7.425000   9.033500   \n",
       "\n",
       "   SMOG Index  Automated Readability Index  Coleman-Liau Index  \\\n",
       "0         0.0                    14.341667             14.3775   \n",
       "1         0.0                    13.972000             13.1584   \n",
       "2         0.0                    11.060000             10.1776   \n",
       "3         0.0                    14.224000             14.2600   \n",
       "4         0.0                     7.300000              5.5955   \n",
       "\n",
       "   Linsear Write Formula  Dale-Chall Readability Score  ...  Comma  Colon  \\\n",
       "0                 12.375                      8.346667  ...   0.21   0.21   \n",
       "1                 12.180                      8.463200  ...   0.21   0.41   \n",
       "2                 11.440                      6.477600  ...   0.21   0.00   \n",
       "3                 12.840                      7.620400  ...   0.20   0.20   \n",
       "4                 10.550                      4.569500  ...   0.26   0.26   \n",
       "\n",
       "   SemiC  QMark  Exclam  Dash  Quote  Apostro  Parenth  OtherP  \n",
       "0   0.21   0.42    0.21  0.21   1.05     0.84     0.42    0.21  \n",
       "1   0.21   0.21    0.21  0.21   0.41     0.41     0.41    0.21  \n",
       "2   0.21   0.21    0.21  0.21   0.62     0.41     0.21    0.21  \n",
       "3   0.20   0.80    0.20  0.20   0.00     0.20     0.00    0.20  \n",
       "4   0.26   1.02    2.55  0.77   0.77     1.02     0.51    0.26  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filename = combine['Filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = combine.drop(columns =  ['Filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UID',\n",
       " 'Flesch Reading Ease',\n",
       " 'Flesch-Kincaid',\n",
       " 'Fog Scale',\n",
       " 'SMOG Index',\n",
       " 'Automated Readability Index',\n",
       " 'Coleman-Liau Index',\n",
       " 'Linsear Write Formula',\n",
       " 'Dale-Chall Readability Score',\n",
       " 'WC',\n",
       " 'Analytic',\n",
       " 'Clout',\n",
       " 'Authentic',\n",
       " 'Tone',\n",
       " 'WPS',\n",
       " 'Sixltr',\n",
       " 'Dic',\n",
       " 'function',\n",
       " 'pronoun',\n",
       " 'ppron',\n",
       " 'i',\n",
       " 'we',\n",
       " 'you',\n",
       " 'shehe',\n",
       " 'they',\n",
       " 'ipron',\n",
       " 'article',\n",
       " 'prep',\n",
       " 'auxverb',\n",
       " 'adverb',\n",
       " 'conj',\n",
       " 'negate',\n",
       " 'verb',\n",
       " 'adj',\n",
       " 'compare',\n",
       " 'interrog',\n",
       " 'number',\n",
       " 'quant',\n",
       " 'affect',\n",
       " 'posemo',\n",
       " 'negemo',\n",
       " 'anx',\n",
       " 'anger',\n",
       " 'sad',\n",
       " 'social',\n",
       " 'family',\n",
       " 'friend',\n",
       " 'female',\n",
       " 'male',\n",
       " 'cogproc',\n",
       " 'insight',\n",
       " 'cause',\n",
       " 'discrep',\n",
       " 'tentat',\n",
       " 'certain',\n",
       " 'differ',\n",
       " 'percept',\n",
       " 'see',\n",
       " 'hear',\n",
       " 'feel',\n",
       " 'bio',\n",
       " 'body',\n",
       " 'health',\n",
       " 'sexual',\n",
       " 'ingest',\n",
       " 'drives',\n",
       " 'affiliation',\n",
       " 'achieve',\n",
       " 'power',\n",
       " 'reward',\n",
       " 'risk',\n",
       " 'focuspast',\n",
       " 'focuspresent',\n",
       " 'focusfuture',\n",
       " 'relativ',\n",
       " 'motion',\n",
       " 'space',\n",
       " 'time',\n",
       " 'work',\n",
       " 'leisure',\n",
       " 'home',\n",
       " 'money',\n",
       " 'relig',\n",
       " 'death',\n",
       " 'informal',\n",
       " 'swear',\n",
       " 'netspeak',\n",
       " 'assent',\n",
       " 'nonflu',\n",
       " 'filler',\n",
       " 'AllPunc',\n",
       " 'Period',\n",
       " 'Comma',\n",
       " 'Colon',\n",
       " 'SemiC',\n",
       " 'QMark',\n",
       " 'Exclam',\n",
       " 'Dash',\n",
       " 'Quote',\n",
       " 'Apostro',\n",
       " 'Parenth',\n",
       " 'OtherP']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combine.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adaku\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data, label, clf):\n",
    "            \n",
    "    data = data.drop(['UID'], axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, label, stratify = label, test_size = 0.2, random_state = 1234)\n",
    "    \n",
    "    if clf == 'rf':\n",
    "        clf = RandomForestClassifier(random_state=1234,n_estimators=150,n_jobs=-1)\n",
    "    elif clf == 'nb':\n",
    "        clf = GaussianNB()\n",
    "    elif clf == 'svm':\n",
    "        clf = svm.SVC(kernel='linear', gamma=\"auto\")\n",
    "    elif clf == 'dt':\n",
    "        clf = DecisionTreeClassifier(random_state=1234)\n",
    "    elif clf == 'lg':\n",
    "        clf = LogisticRegression(random_state=1234)\n",
    "\n",
    "\n",
    "    names = list(data.columns)\n",
    "    train_vector = X_train\n",
    "    test_vector = X_test\n",
    "\n",
    "    \n",
    "    fit = clf.fit(train_vector,y_train)\n",
    "    pred = clf.predict(test_vector)\n",
    "    \n",
    "#     # Instantiate the classification model and visualizer\n",
    "#     visualizer = ClassPredictionError(clf, classes= ['human', 'ctrl', 'gpt', 'gpt2', 'grover', 'xlm', 'xlnet', 'pplm', 'fair'])\n",
    "\n",
    "#     # Fit the training data to the visualizer\n",
    "#     visualizer.fit(train_vector, y_train)\n",
    "\n",
    "#     # Evaluate the model on the test data\n",
    "#     visualizer.score(test_vector, y_test)\n",
    "\n",
    "#     # Draw visualization\n",
    "#     visualizer.show()\n",
    "    \n",
    "    \n",
    "    matrix = confusion_matrix(y_test, pred, labels = ['ctrl', 'gpt', 'gpt2', 'grover', 'xlm', 'xlnet', 'pplm', 'human', 'fair'])\n",
    "    mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    print(classification_report(y_test, pred, labels = ['ctrl', 'gpt', 'gpt2', 'grover','xlm', 'xlnet', 'pplm', 'human', 'fair'],\n",
    "                                digits=4))\n",
    "    print('confusion matrix: ', mat)\n",
    "    \n",
    "    Accuracy = accuracy_score(y_test,pred)\n",
    "    F1 = f1_score(y_test, pred, average='macro')\n",
    "    print(\"Accuracy:\", Accuracy)\n",
    "    \n",
    "    rec = recall_score(y_test, pred, average='macro')\n",
    "    print('Recall: ', rec)\n",
    "    prec = precision_score(y_test, pred, average='macro')\n",
    "    print('Precision: ', prec)\n",
    "    \n",
    "    print('F1:', F1)\n",
    "    \n",
    "    return clf, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl     0.9953    1.0000    0.9977       213\n",
      "         gpt     0.9906    0.9906    0.9906       213\n",
      "        gpt2     0.8000    0.7477    0.7729       214\n",
      "      grover     0.7479    0.8216    0.7830       213\n",
      "         xlm     1.0000    1.0000    1.0000       213\n",
      "       xlnet     1.0000    1.0000    1.0000       213\n",
      "        pplm     0.9814    0.9860    0.9837       214\n",
      "       human     0.9130    0.7887    0.8463       213\n",
      "        fair     0.6738    0.7371    0.7040       213\n",
      "\n",
      "    accuracy                         0.8968      1919\n",
      "   macro avg     0.9002    0.8969    0.8976      1919\n",
      "weighted avg     0.9002    0.8968    0.8976      1919\n",
      "\n",
      "confusion matrix:  [1.         0.99061033 0.74766355 0.82159624 1.         1.\n",
      " 0.98598131 0.78873239 0.7370892 ]\n",
      "Accuracy: 0.8968212610734758\n",
      "Recall:  0.8968525587585743\n",
      "Precision:  0.9002288054325369\n",
      "F1: 0.897586610689561\n"
     ]
    }
   ],
   "source": [
    "clf_rf, names_rf = classify(combine, label, 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl     0.9631    0.9812    0.9721       213\n",
      "         gpt     0.9811    0.9765    0.9788       213\n",
      "        gpt2     0.6241    0.3879    0.4784       214\n",
      "      grover     0.3548    0.1033    0.1600       213\n",
      "         xlm     0.9858    0.9765    0.9811       213\n",
      "       xlnet     0.9952    0.9671    0.9810       213\n",
      "        pplm     0.9704    0.9206    0.9448       214\n",
      "       human     0.3077    0.8826    0.4563       213\n",
      "        fair     0.3968    0.1174    0.1812       213\n",
      "\n",
      "    accuracy                         0.7014      1919\n",
      "   macro avg     0.7310    0.7015    0.6815      1919\n",
      "weighted avg     0.7311    0.7014    0.6816      1919\n",
      "\n",
      "confusion matrix:  [0.98122066 0.97652582 0.38785047 0.10328638 0.97652582 0.96713615\n",
      " 0.92056075 0.88262911 0.11737089]\n",
      "Accuracy: 0.7014069828035435\n",
      "Recall:  0.7014562278482247\n",
      "Precision:  0.7310085225551536\n",
      "F1: 0.6815223778711531\n"
     ]
    }
   ],
   "source": [
    "clf_nb, names_nb = classify(combine, label, 'nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl     0.9907    0.9953    0.9930       213\n",
      "         gpt     0.9861    1.0000    0.9930       213\n",
      "        gpt2     0.7879    0.7290    0.7573       214\n",
      "      grover     0.7315    0.7418    0.7366       213\n",
      "         xlm     0.9861    1.0000    0.9930       213\n",
      "       xlnet     1.0000    0.9953    0.9976       213\n",
      "        pplm     0.9718    0.9673    0.9696       214\n",
      "       human     0.8010    0.7746    0.7876       213\n",
      "        fair     0.6228    0.6667    0.6440       213\n",
      "\n",
      "    accuracy                         0.8744      1919\n",
      "   macro avg     0.8753    0.8744    0.8746      1919\n",
      "weighted avg     0.8753    0.8744    0.8746      1919\n",
      "\n",
      "confusion matrix:  [0.99530516 1.         0.72897196 0.74178404 1.         0.99530516\n",
      " 0.96728972 0.77464789 0.66666667]\n",
      "Accuracy: 0.8744137571651902\n",
      "Recall:  0.8744411780478649\n",
      "Precision:  0.8753161749373032\n",
      "F1: 0.8746276708165435\n"
     ]
    }
   ],
   "source": [
    "clf_svm, names_svm = classify(combine, label, 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl     0.9952    0.9812    0.9882       213\n",
      "         gpt     0.9765    0.9765    0.9765       213\n",
      "        gpt2     0.5981    0.5981    0.5981       214\n",
      "      grover     0.6432    0.6432    0.6432       213\n",
      "         xlm     0.9953    0.9859    0.9906       213\n",
      "       xlnet     0.9906    0.9906    0.9906       213\n",
      "        pplm     0.9412    0.9720    0.9563       214\n",
      "       human     0.7523    0.7700    0.7610       213\n",
      "        fair     0.5485    0.5305    0.5394       213\n",
      "\n",
      "    accuracy                         0.8275      1919\n",
      "   macro avg     0.8268    0.8276    0.8271      1919\n",
      "weighted avg     0.8267    0.8275    0.8271      1919\n",
      "\n",
      "confusion matrix:  [0.98122066 0.97652582 0.59813084 0.64319249 0.98591549 0.99061033\n",
      " 0.97196262 0.76995305 0.53051643]\n",
      "Accuracy: 0.8275143303804064\n",
      "Recall:  0.8275586366938217\n",
      "Precision:  0.8267746640282919\n",
      "F1: 0.8271030424530065\n"
     ]
    }
   ],
   "source": [
    "clf_dt, names_dt = classify(combine, label, 'dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl     0.9269    0.9531    0.9398       213\n",
      "         gpt     0.8903    0.9906    0.9378       213\n",
      "        gpt2     0.5094    0.6308    0.5637       214\n",
      "      grover     0.6316    0.3380    0.4404       213\n",
      "         xlm     0.9286    0.9765    0.9519       213\n",
      "       xlnet     0.9810    0.9718    0.9764       213\n",
      "        pplm     0.9358    0.9533    0.9444       214\n",
      "       human     0.5622    0.4883    0.5226       213\n",
      "        fair     0.4309    0.4977    0.4619       213\n",
      "\n",
      "    accuracy                         0.7556      1919\n",
      "   macro avg     0.7552    0.7556    0.7488      1919\n",
      "weighted avg     0.7552    0.7556    0.7488      1919\n",
      "\n",
      "confusion matrix:  [0.95305164 0.99061033 0.63084112 0.33802817 0.97652582 0.97183099\n",
      " 0.95327103 0.48826291 0.49765258]\n",
      "Accuracy: 0.7556018759770714\n",
      "Recall:  0.7555638434274738\n",
      "Precision:  0.7551888086411829\n",
      "F1: 0.7487694676799166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adaku\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "clf_lg = classify(combine, label, 'lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = clf_rf.get_feature_names()\n",
    "importance = clf_rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WC</td>\n",
       "      <td>0.089597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>article</td>\n",
       "      <td>0.076895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Period</td>\n",
       "      <td>0.040703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WPS</td>\n",
       "      <td>0.038802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>prep</td>\n",
       "      <td>0.036229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Comma</td>\n",
       "      <td>0.034597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>auxverb</td>\n",
       "      <td>0.033147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>function</td>\n",
       "      <td>0.027591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>AllPunc</td>\n",
       "      <td>0.026554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ppron</td>\n",
       "      <td>0.022906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Importance\n",
       "8         WC    0.089597\n",
       "25   article    0.076895\n",
       "90    Period    0.040703\n",
       "13       WPS    0.038802\n",
       "26      prep    0.036229\n",
       "91     Comma    0.034597\n",
       "27   auxverb    0.033147\n",
       "16  function    0.027591\n",
       "89   AllPunc    0.026554\n",
       "18     ppron    0.022906"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impordf = pd.DataFrame({'Word' : names_rf,'Importance' : importance})\n",
    "impordf = impordf.sort_values(['Importance', 'Word'], ascending=[0, 1])\n",
    "impordf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-f998d1a871cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# words = clf_rf.get_feature_names()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimportance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_svm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimpordf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Word'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mnames_svm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Importance'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mimportance\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimpordf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimpordf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Importance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Word'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimpordf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "# words = clf_rf.get_feature_names()\n",
    "importance = clf_svm.feature_importances_\n",
    "impordf = pd.DataFrame({'Word' : names_svm,'Importance' : importance})\n",
    "impordf = impordf.sort_values(['Importance', 'Word'], ascending=[0, 1])\n",
    "impordf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GaussianNB' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-25e17f2188ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# words = clf_rf.get_feature_names()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimportance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_nb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimpordf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Word'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mnames_nb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Importance'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mimportance\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimpordf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimpordf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Importance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Word'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimpordf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GaussianNB' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "# words = clf_rf.get_feature_names()\n",
    "importance = clf_nb.feature_importances_\n",
    "impordf = pd.DataFrame({'Word' : names_nb,'Importance' : importance})\n",
    "impordf = impordf.sort_values(['Importance', 'Word'], ascending=[0, 1])\n",
    "impordf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WC</td>\n",
       "      <td>0.265123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>article</td>\n",
       "      <td>0.146305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WPS</td>\n",
       "      <td>0.120592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>auxverb</td>\n",
       "      <td>0.119444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ppron</td>\n",
       "      <td>0.092068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Colon</td>\n",
       "      <td>0.019470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>adverb</td>\n",
       "      <td>0.010974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Comma</td>\n",
       "      <td>0.007601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Quote</td>\n",
       "      <td>0.007573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>AllPunc</td>\n",
       "      <td>0.007052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Importance\n",
       "8        WC    0.265123\n",
       "25  article    0.146305\n",
       "13      WPS    0.120592\n",
       "27  auxverb    0.119444\n",
       "18    ppron    0.092068\n",
       "92    Colon    0.019470\n",
       "28   adverb    0.010974\n",
       "91    Comma    0.007601\n",
       "97    Quote    0.007573\n",
       "89  AllPunc    0.007052"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words = clf_rf.get_feature_names()\n",
    "importance = clf_dt.feature_importances_\n",
    "impordf = pd.DataFrame({'Word' : names_dt,'Importance' : importance})\n",
    "impordf = impordf.sort_values(['Importance', 'Word'], ascending=[0, 1])\n",
    "impordf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
